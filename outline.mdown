# Sharding your Rails Database

## (not sharting)

##

## Overview

* Why did we do this?
* What did we do?
* Would we do it again?

----

5 min - our situation
5 min - what is sharding?
5 min - development
5 min - deployment/maintenance
5 min - reporting/end user impact
5 min - results

## Visual ideas

* Heroku pseudoslider
* Choose your own adventure

## Our situation

* Helping kids do math is awesome! (screenshots?)
* Hockey stick growth wooo!
* Expected accelerated growth made everyone crazy
* Limited window for updates (xmas)
* Performance issues, cause of which were unknown
* Database was getting super big -- > mecha!

## What is sharding?

* Horizontal
* Vertical
* Use the 'one table' metaphor
  * Horizontal: split by rows (pictures**)
  * Vertical: split by columns (pictures**)
* We did both! (user data [small] connecting to student activity data
  [HUGE] connecting to math content [small])

## Your special snowflake application

* Everybody is a different snowflake
   * Yammer did it like this (pictures**)
   * Instragram did it like this (pictures**)
   * TTM did it like this (pictures**)
* Main point: they're ALL DIFFERENT
* You have to spend time on this part, and it will be more time than
  you think. (Even when taking into account Hofstadter's Law)
* How many times to distribute: if you only need 4 (like us) do you
  really need sharding?

## What should you do instead?

* Can you archive data? Moving data to read-only solutions can be a
  reliable fix.
  * But it's scary, and maybe not even possible in some industries)
* Normal optimization -- N+1 queries, long SQL queries (boring but effective)
* Caching (it's hard too, but less drastic)
* More hardware! It's really fast now!
* Not virtualization (databases I/O bound)
* If this is your real problem, maybe look into a data warehouse?
  * ...but this takes more time than sharding
  * ...also more of a change to your data and how you think about it

# Development

* Big cost up front, then not as much
* Upfront cost: the part we said would take a long time, learning to
  think in shards, customizing DB Charmer

## Method of sharding in rails

* If vertical only, you can use AR `establish_connection`
* db-charmer gem (show before/after of model with DSL)
  * Switches around the ActiveRecord connection.
* Customizations:
  * associations - once you know what shard one thing is on, it should
    be automatic to know what shard associated objects are on but it
    wasn't
    * Relations (now four types: master-to-master, shard-to-shard,
      master-to-shard, shard-to-master - yay AR for having hooks to
      make this fairly easy)
  * Request store for fallback resolver (we should commit this, sorry)
* Other choices... all seem like whoever wrote them got to whatever
  support they needed and stopped.
* Cutover process

## Talking point issues

* GUIDs (or the general idea of generating unique IDs, important as
  illustration of something you take for granted right now that you
  need to change OR ELSE)
* All your libraries + rake tasks assume one database so they never
  cleanup connections (had to create custom sidekiq middleware to
  cleanup sticky connection)

## Beat them over the head issues
(pictures as bursts**)
* Dev environment gets sharded too, as close as possible to prod
  (but how much did this help?? maybe just mental?)
* ...migrations! (dbcharmer has built-in, but still tricky)
* Tests - factories
* Development - reloading, production db mirrors
* Moving data between shards
* rake db:* expected one db
* db-charmer not threadsafe; sidekiq MUST be CONCURRENCY=1

# Deployment + maintenance
  * Constant pain
  * 'rails console' hack for picking a random shard (YOU ALWAYS HAVE TO DO THIS)

## Talking point issues

* All your services assume one database too (Heroku
  DATABASE_URL + buildpack hacking)
* Queries that need data from > 1 shard will be slow (rewriting left
  joins in code)
* Migrations (those that alter lots of data WILL STILL ALTER LOTS OF
  DATA, can you parallelize?)

## Beat them over the head issues
(pictures as bursts**)
* All the dynos connecting to all the shards (connection limits?)
* Backups - now you have to backup all the dbs!
* Splitting shards (if one gets too big, how to create more)
* Monitoring
* Logging

# Results

## And now...?

* Did expected growth happen? YES. (pictures**)

## Did it help our performance issues?

* Not really. Sharding probably amplified the effect of optimizations
  done right after sharding
* It helped with the database size.
* Real performance bottleneck was heroku random routing in vicious
  cycle with our slow controllers
* Might be good for us for the future.

## Side-effects

* Had to build a DW anyway (fast for DW, but still slower)

## Future plans

* Desharding! Fixes like DW can let you catch up, archive data, and
  not need shards anymore.
  * Because we did the ID work, this should be easy! (in theory...)
  * ...back to normal Rails land. (Do you rip out all the sharding breadcrumbs?)
* SOA Amazon-style
* Less fragile sharding schemes so that moving student data is easier
* Geographic colocation (possibility if we de-shard)

## Would we do it again with 20/20 hindsight?

* No -- optimize first and iterate
* Knowing that the hockey stick wasn't forever we didn't need THAT
  much more ceiling
* Best case would be to have analytics to prove that the db  the
  bottleneck.

## Should you do it?

* Almost certainly not.
* Definitely not out of the gate.
* Your special snowflakeness will override any technology choices.
* Good luck!

----------------------------------------

## What do normal humans think

* Had to sell to business that we were doing this instead of features
* Had to stop content editing

## Other things to do to address these issues instead of sharding

* Caching
* SQL query optimization
* Individual action performance tuning
* Archiving data
* Begging Heroku for help/configuration/bigger dbs or dynos
* More + better-used hardware

## Why did we choose sharding?

* The Nuclear Option
* Best chance with the window available to provide the biggest bang
  for our buck, give us the most space to grow
* Many smaller databases instead of one big one
* Scaling to infinity and beyond (theoretically)
  * Ideally, route requests to particular shards

## Lingo

* "Vertical partition" <=> "Master shard"

# Resources

* http://eng.yammer.com/sharding-a-large-rails-app/
* http://instagram-engineering.tumblr.com/post/40781627982/handling-growth-with-postgres-5-tips-from-instagram
* http://instagram-engineering.tumblr.com/post/10853187575/sharding-ids-at-instagram
* Craig Kerstiens' post
  * http://www.craigkerstiens.com/2012/11/30/sharding-your-database/
* Werner Vogels podcast on Amazon SOA
  * http://www.se-radio.net/2006/12/episode-40-interview-werner-vogels/

# Out of scope

* Replication
